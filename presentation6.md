# 분류에서의 통계학

## 데이터

### 독립성
> **[독립성의 중요성]**
>
> (확률)변수들 간의 독립성을 의미하며, 하나의 변수가 다른 변수에 영향을 미치지 않는 상태를 말한다. 
>  
> 독립성 가정은 많은 통계적 검정에서 기본 가정으로 사용된다.

### 통계적 검정
데이터의 전수 조사는 실제로 불가능한 경우가 많으므로, 통계학적 추정과 검정을 통해 의사 결정을 내린다. 이는 데이터가 가설을 잘 따르는지 판단할 수 있게 한다.

> **[통계적 검정의 기본]**
> 
> **귀무 가설**과 **대립 가설**을 먼저 설정한다. 각 가설은 서로 대립하는 주장을 펼친다. 각 가설의 기각 여부는 일반적인 방법으로 **검정통계량**을 바탕으로 한다. 
>
> **검정통계량**을 바탕으로 ```귀무 가설을 기각한다.```, 또는 ```귀무 가설을 기각하지 않는다.``` 이렇게 두 가지의 의사 결정을 내릴 수 있다. 이 때 **신뢰 구간**과 **기각역**을 근거로 결정을 내리게 된다.
>
> ![image](https://github.com/user-attachments/assets/86704e12-b9cd-4188-ac29-769f53a70a71)
>
> **[주요 기법]**:
> - **카이제곱 검정** : 범주형 데이터에서 두 변수 간 관계를 분석하는 방법.
>   - *적합도* : 범주형 데이터에서의 그룹의 비율, 그룹의 분포 등을 비교 검정.
>   - *독립성* : 두 범주형 데이터 간 관계를 검정.
>   - *동질성* : 데이터 그룹에 대응하는 분포를 검정.
>   ![image](https://github.com/user-attachments/assets/a7fef6cb-5bdf-4038-af53-35b4e9991fff)


> - **t-검정** : 두 그룹 간의 평균 차이를 비교하는 방법.

### 차원 핸들링
- **정의**: 고차원의 데이터에서 불필요한 차원을 줄이는 과정을 의미합니다.
- **기법**:
  - **차원 축소**: PCA(주성분 분석), LDA(선형 판별 분석) 등을 통해 차원을 줄여 데이터의 복잡성을 낮춥니다.
  - **특성 선택**: 모델 성능 향상을 위해 중요한 특성을 선택하는 방법.

### 특성 분석
- **정의**: 주어진 데이터에서 각 특성(Feature)의 중요도를 평가하고 분석하는 과정입니다.
- **중요성**: 중요한 특성은 모델의 성능에 큰 영향을 미치며, 불필요한 특성 제거 시 과적합을 방지할 수 있습니다.

## 분류기

### 베이즈 정리 & 나이브 베이즈
- **베이즈 정리**: 조건부 확률을 기반으로 사전 확률을 갱신하는 방법.
- **나이브 베이즈**: 모든 특성 간의 독립성을 가정하여 베이즈 정리를 적용하는 간단하면서도 강력한 분류 알고리즘.

### 최대우도법
- **정의**: 주어진 데이터가 가장 일어날 가능성을 최대화하는 매개변수를 찾는 방법론.
- **사용 사례**: 회귀 분석, 통계 모델링 등에서 사용되며, 특히 확률 모델의 매개변수를 추정하는 데 자주 사용됩니다.

### 로지스틱 회귀
- **정의**: 이진 분류 문제에서 사용되는 선형 모델의 일종으로, 데이터가 특정 클래스에 속할 확률을 추정합니다.
- **특징**: 시그모이드 함수를 사용하여 출력이 0과 1 사이의 값을 가지며, 이를 통해 분류 작업을 수행합니다.

## 평가

### 신뢰 구간
- **정의**: 모집단의 특정 모수(parameter)가 포함될 것으로 예상되는 범위를 말합니다.
- **중요성**: 모델의 예측 결과에 대한 불확실성을 정량화하여 결과의 신뢰성을 평가할 수 있습니다.

### 혼동 행렬
- **정의**: 분류 모델의 성능을 평가하기 위해 실제 값과 예

